Feature Engineering & Data Preprocessing

This repository demonstrates core feature engineering and preprocessing techniques in machine learning. These steps prepare raw data to improve model performance and learning efficiency.

Techniques Covered

Binning (Discretization)

Converts continuous numeric data into discrete categories (bins).

Example: Age â†’ Teen / Adult / Senior.

Transforming

Changes feature distribution or scale to reduce skewness or outliers.

Examples: Log, Square Root, Box-Cox, Yeo-Johnson, Normalization.

Encoding

Converts categorical data into numeric form for ML models.

Types:

Label Encoding (ordered categories)

One-Hot Encoding (independent categories)

Binary / Target Encoding (high-cardinality categories)

Scaling

Standardizes feature ranges to ensure no feature dominates.

Methods: Min-Max Scaling, Standardization (Z-score), Robust Scaling.

Shuffling

Randomly rearranges data to remove order bias and improve generalization.
